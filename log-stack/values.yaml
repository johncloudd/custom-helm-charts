# Default values for log-stack.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
replicaCount: 1

environment: tools


# FluentD config:
fluentd_image: gcr.io/google-containers/fluentd-elasticsearch
fluentd_imageTag: v2.0.4

domain: mydomain

tld: com

## Specify an imagePullPolicy (Required)
## It's recommended to change this to 'Always' if the image tag is 'latest'
## ref: http://kubernetes.io/docs/user-guide/images/#updating-images
imagePullPolicy: IfNotPresent
 
## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  limits:
    cpu: 100m
    memory: 150Mi
  requests:
    cpu: 100m
    memory: 150Mi

## Add tolerations if specified
# tolerations:
#   - key: node-role.kubernetes.io/master
#     operator: Exists
#     effect: NoSchedule

elasticsearch:
  host: 'elasticsearch-client-svc-tools.default.svc.cluster.local'
  port: 9200
  buffer_chunk_limit: 8M
  buffer_queue_limit: 8

# Whitelisted IPs from foreign logstash instances to ES master in tools VPC.
Whitelist:

configMaps:
  output.conf: |
    <filter kubernetes.**>
      @type record_transformer
      <record>
        k8s_cluster "tools-#{ENV['ENVIRONMENT']}"
      </record>
    </filter>

    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>

    <filter kubernetes.**>
      @type grep

      <exclude>
        key $.kubernetes.pod_name
        pattern calico
      </exclude>
    </filter>

    <filter kubernetes.**>
      @type grep
      <exclude>
        key $.kubernetes.pod_name
        pattern fluentd
      </exclude>

    </filter>

    <match **> 
      @id elasticsearch
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['OUTPUT_HOST']}"
      port "#{ENV['OUTPUT_PORT']}"
      logstash_format true
      reload_connections false

      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 2
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
        queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
        overflow_action block
      </buffer>
    </match>

# fluentdcustomconfig: |
#   # add fluentd custom configs here
# Default values for logstash.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.


# logstash stuff
logstash_replicaCount: 1
logstash_nodeSelector: {}
logstash_image:
  logstash_repository: prominentedgestatengine/logstash
  logstash_tag: 6.2.1
  logstash_pullPolicy: IfNotPresent
logstash_service:
  logstash_type: ClusterIP
  logstash_internalPort: 1514
  logstash_ports:
    - name: "syslog-tcp"
      protocol: TCP
      containerPort: 1514
    - name: "filebeat-tcp"
      protocol: TCP
      containerPort: 5044

# Extra config options
logstash_configData: {}

logstash_podAnnotations: {}
  # Add custom annotations to pods
  # iam.amazonaws.com/role: "example-role"

logstash_podLabels: {}
  # Add custom labels to pods
  # team: "developers"
  # service: "logstash"

logstash_livenessProbe:
  logstash_initialDelaySeconds: 60
  logstash_periodSeconds: 20
logstash_readinessProbe:
  logstash_initialDelaySeconds: 120

logstash_ingress:
  logstash_enabled: false
  # Used to create an Ingress and Service record.
  # hosts:
  #   - name: "logstash_udp.local"
  #     protocol: UDP
  #     serviceName: logstash_udp
  #     servicePort: 514
  logstash_annotations:
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  logstash_tls:
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local
logstash_resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 300Mi
  # requests:
  #   cpu: 100m
  #   memory: 300Mi

logstash_elasticsearch:
  logstash_host: "elasticsearch-client-svc-tools.default.svc.cluster.local"
  logstash_port: 9200

# patterns for filters
# each element will be turned into it's own pattern file
logstash_patterns:
  # testpattern: |-
  #     TESTING {"foo":.*}$

logstash_inputs:
  logstash_main: |-
    input {
      tcp {
        port => "${SYSLOG_PORT}"
        type => syslog
      }
      beats {
        port => 5044
        tags => ["filebeat"]
      }
      elasticsearch {
        hosts => "http://elasticsearch-client-svc-tools.default.svc.cluster.local:9200"
        index => "logstash-*"
        query => '{ "query": { "query_string": { "query": "kubernetes.labels.app: ingress-nginx" } } }'
        tags => ["nginx"]
        schedule => "* * * * *"
      }   
      elasticsearch {
        hosts => "http://elasticsearch-client-svc-tools.default.svc.cluster.local:9200"
        index => "filebeat-6.2.3*"
        tags => ["filebeat"]
        schedule => "* * * * *"
      }   
    }   

logstash_filters:
  logstash_main: |-
    filter {
      if "nginx" in [tags] {
        grok {
          match => { "log" => "%{IPORHOST:clientip} %{DATA:ident} %{DATA:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) (?:\"(?:%{URI:referrer}|-)\"|%{QS:referrer}) %{QS:agent}" }
        }   

        geoip {
          database => "/opt/maxmind/GeoLite2-City.mmdb"
          source => "clientip"
        }   

        mutate {
          copy => { "geoip" => "geo_point" }
          add_field => {"[location][lat]" => "%{[geoip][latitude]}"}
          add_field => {"[location][lon]" => "%{[geoip][longitude]}"}
        } 
        mutate {
          copy => { "geoip" => "geo_point" }
          add_field => {"[location][lat]" => "%{[geoip][latitude]}"}
          add_field => {"[location][lon]" => "%{[geoip][longitude]}"}
        }   

        mutate {
          convert => { "bytes" => "integer" }
        }   
  
     } else if "filebeat" in [tags] {

        grok {
          match => { "message" => "%{IPV4:clientip2}" }
        }
        geoip {
          database => "/opt/maxmind/GeoLite2-City.mmdb"
          source => "clientip2"
        }
      }

    }   


logstash_outputs:
  logstash_main: |-
    output {
     if "nginx" in [tags] {
        elasticsearch {
          hosts => ["http://elasticsearch-client-svc-tools.default.svc.cluster.local:9200"]
          index => "nginx-filtered-%{+YYYY.MM.dd}"
        }
     } else if "filebeat" in [tags] {
        elasticsearch {
          hosts => ["http://elasticsearch-client-svc-tools.default.svc.cluster.local:9200"]
          index => "filebeat-filtered-%{+YYYY.MM.dd}"
        }
     }
    }

# ES settings:
Persistence:
  Size: "300Gi"
  StorageClassName: "elasticsearch-hot"

appVersion: 6.2.2

image:
  repository: "docker.elastic.co/elasticsearch/elasticsearch"
  tag: "6.2.2"
  pullPolicy: "Always"

cluster:
  name: "elasticsearch"
  config:
  env:
    # IMPORTANT: https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html#minimum_master_nodes
    # To prevent data loss, it is vital to configure the discovery.zen.minimum_master_nodes setting so that each master-eligible
    # node knows the minimum number of master-eligible nodes that must be visible in order to form a cluster.
    MINIMUM_MASTER_NODES: "3" 
    EXPECTED_MASTER_NODES: "4" 

client:
  nodeSelector:
    cluster-type: es-coordinators-development
  name: client
  replicas: 3
  serviceType: ClusterIP
  heapSize: "3000m"
  antiAffinity: "hard"
  resources:
    limits:
      #cpu: "8`"
      #memory: "7505Mi"
    requests:
      #cpu: "25m"
      #memory: "7505Mi"

master:
  nodeSelector:
    cluster-type: es-masters-development
  name: master
  replicas: 3
  heapSize: "4000m"
  storage: "100Gi"
  storageClass: "elasticsearch-master"
  antiAffinity: "hard"
  resources:
    limits:
      #cpu: "8"
      #memory: "7505Mi"
    requests:
      #cpu: "25m"
      #memory: "7505Mi"

data:
  expected_total: 4
  replicas: 2
  nodeSelector:
    cluster-type: es-data-development
  name: data
  heapSize: "3000m"
  storage: "400Gi"
  storageClass: "elasticsearch"
  terminationGracePeriodSeconds: 10
  antiAffinity: "hard"
  resources:
    limits:
      #cpu: "8"
      #memory: "7505Mi"
    requests:
      #cpu: "25m"
      #memory: "7505Mi"

shards:
  allow_rebalance_on_rollover: true
  shards_limit: true
  shards_per_node: 200 

## Install Default RBAC roles and bindings
rbac:
  create: true


# Kibana Settings:

kibana_image:
  kibana_repository: "docker.elastic.co/kibana/kibana-oss"
  kibana_tag: "6.2.2"
  kibana_pullPolicy: "IfNotPresent"

kibana_env:
  # All Kibana configuration options are adjustable via env vars.
  # To adjust a config option to an env var uppercase + replace `.` with `_`
  # Ref: https://www.elastic.co/guide/en/kibana/current/settings.html
  #
  ELASTICSEARCH_URL: http://elasticsearch-client-svc-tools.default.svc.cluster.local:9200
  SERVER_PORT: 5601
  LOGGING_VERBOSE: "true"
  SERVER_DEFAULTROUTE: "/app/kibana"

kibana_service:
  kibana_type: ClusterIP
  kibana_externalPort: 80
  kibana_internalPort: 5601
  ## External IP addresses of service
  ## Default: nil
  ##
  # externalIPs:
  # - 192.168.0.1

kibana_ingress:
  kibana_enabled: false
  # hosts:
    # - chart-example.local
  # annotations:
  #   kubernetes.io/ingress.class: nginx
  #   kubernetes.io/tls-acme: "true"
  # tls:
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

kibana_resources:
  limits:
    cpu: 100m
    memory: 300Mi
  requests:
    cpu: 100m
    memory: 300Mi

# Affinity for pod assignment
# Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
# affinity: {}

# Tolerations for pod assignment
# Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
kibana_tolerations: []

# Node labels for pod assignment
# Ref: https://kubernetes.io/docs/user-guide/node-selection/
kibana_nodeSelector: {}

kibana_podAnnotations: {}
kibana_replicaCount: 1
